{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "035bf2c1-b4a8-4442-8a74-ca188f1d1854",
   "metadata": {},
   "source": [
    "## CodeGrade Assignment — Tutorial and Template\n",
    "_Maxim van den Berg (reach me for any questions via maximvdberg@gmail.com)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5646749c-6b6f-4e1b-a4c5-5158b4cc3c8b",
   "metadata": {},
   "source": [
    "This is tutorial and template for creating notebook assignments graded through CodeGrade. You can write the assignments, solutions and autotests all in this document. Then by running \n",
    "```bash\n",
    "$ python prepare.py assignment [solution notebook].ipynb [student notebook].ipynb\n",
    "``` \n",
    "you remove the solutions and autotests, and you can upload the resulting notebook for your students to Canvas.\n",
    "\n",
    "You need to have the `nbconvert` python package installed for the script to work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3e12bf-550a-4d4a-9946-108d0730e9d7",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Using this document](#using-this-document)\n",
    "2. [Creating autotests](#creating-autotests)\n",
    "3. [Checking tests locally](#checking-tests-locally)\n",
    "4. [Setting up CodeGrade](#codegrade)\n",
    "5. [Student feedback](#student-feedback)\n",
    "6. [Optional: Making the solutions available to students](#solutions)\n",
    "7. [Optional: Link tests to specific CodeGrade rubrics](#specific-rubrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93278ba4-d7bf-486b-b9fb-695309461bb9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1 Using this document <a class=\"anchor\" id=\"using-this-document\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fbc817-7d09-4580-881e-93b93a7fbf9e",
   "metadata": {},
   "source": [
    "In these cells you write your assignment information. $\\LaTeX$ is supported. In the cell below student can write their solution (although they can put in anywhere in the notebook). Make sure students use the correct variable and function names, for instance by writing them in the cell already. Do not use the same name twice in the notebook, as it breaks the autotests.\n",
    "\n",
    "Write the solution between `#!# BEGIN SOLUTION` and `#!# END SOLUTION`. This will be automatically removed and replaced with `#. Your solution here ...` in the student notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b2eef96-936a-4c3f-a988-20fd0e30468b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#!# BEGIN SOLUTION\n",
    "answer = 10\n",
    "#!# END SOLUTION\n",
    "# answer = ...\n",
    "\n",
    "def add(a, b):\n",
    "    #!# BEGIN SOLUTION\n",
    "    return a + b\n",
    "    #!# END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6096763d-b35e-473f-ad75-d889e2cb1288",
   "metadata": {},
   "source": [
    "You can also simply tell to student to \"implement the `add(a, b)` function\" and write the cell like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ce2dc6f-0c48-4f0f-a36f-649ef6e18b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!# BEGIN SOLUTION\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "#!# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c5c19b-6318-45a2-ac1b-c33a18b7ef2c",
   "metadata": {},
   "source": [
    "You can also create solution blocks in markdown cells, for instance when the students have to give a LaTeX or written answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6894e-9fd7-4bff-905a-4d277daa1228",
   "metadata": {},
   "source": [
    "#!# BEGIN SOLUTION\n",
    "\n",
    "The answer is\n",
    "$$ \n",
    "    p_X(k) = \\binom{n}{k} p^k (1-p)^{n-k}.\n",
    "$$\n",
    "\n",
    "#!# END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1af9272-4813-4432-b169-6b71a36c48d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2 Creating autotests <a class=\"anchor\" id=\"creating-autotests\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb9cffb-59e0-4679-a3ac-730f9815da82",
   "metadata": {},
   "source": [
    "Write the tests between `#!# BEGIN VISIBLE TESTS` and `#!# END VISIBLE TESTS` or `#!# BEGIN HIDDEN TESTS` and `#!# END HIDDEN TESTS`. Both will be automatically removed in the student notebook. The first category will be visible for students on CodeGrade after handing in. The second will only become visible after the deadline has passed.\n",
    "\n",
    "The tests use [pytest](https://docs.pytest.org/en/7.4.x/). Every test is a function that starts with `test_` and takes no arguments. PyTests gives full points if all `assert`-statements in the function evaluate to `True`. \n",
    "\n",
    "The students solutions will be available in the `student` module, so for testing the student code all variables/functions should start with `student.`. If multiple functions depend on each other, it is recommended to use `student.` only for the function being tested, to avoid continuous errors. The tests can access all variables and functions in the solution notebook directly.\n",
    "\n",
    "The `weight`, `name` and `description` decorators link up with CodeGrade when we run the tests there. The `name` and `description` are what the students will see in CodeGrade, and should tell te students to which assignment the test belongs. Recommended is to set `name` to the assignment name (for example `\"Question 1, part (a)\"`). The `description` decorator is optional, but recommended to improve clarity (for example `\"Test the add function\"`). \n",
    "\n",
    "See the code below for examples and some additional testing tips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "928d089d-bfc3-42e7-8021-0ce98d166960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: \t 1\n",
      "name: \t\t A name for the test\n",
      "description: \t A description of the test\n",
      "Test OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!# BEGIN VISIBLE TESTS\n",
    "@weight(1)\n",
    "@name(\"A name for the test\")\n",
    "@description(\"A description of the test\")\n",
    "def test_add_single():\n",
    "    assert student.add(10,12) == add(10,12), \"Add was incorrect\" \n",
    "                                             # ^ This string will be reported to students in CodeGrade when assert fails.\n",
    "#!# END VISIBLE TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58f7b50e-7462-4b34-9d65-35a09db070d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: \t 0\n",
      "name: \t\t Add function — no build-in\n",
      "description: \t Check the add function doesn't use a build-in function\n",
      "Test OK\n",
      "\n",
      "weight: \t 3\n",
      "name: \t\t Add function — test multiple values\n",
      "description: \t Test the add function on more inputs\n",
      "Test OK\n",
      "\n",
      "weight: \t 2.5\n",
      "name: \t\t Add function — test multiple values\n",
      "description: \t Test the add function on more inputs\n",
      "Test OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!# BEGIN VISIBLE TESTS\n",
    "# You can check for strings in the student's implemention.\n",
    "import re, inspect\n",
    "\n",
    "@weight(0) # <- You can set weight to zero, just for student feedback\n",
    "@name(\"Add function — no build-in\")\n",
    "@description(\"Check the add function doesn't use a build-in function\")\n",
    "def test_add_no_buildin_function():\n",
    "    source = re.sub(r\"#.*\", \"\", inspect.getsource(student.add))\n",
    "    assert not \"np.add\" in source, \"Use of numpy's build-in add function is not allowed\"\n",
    "#!# END VISIBLE TESTS\n",
    "\n",
    "\n",
    "#!# BEGIN HIDDEN TESTS\n",
    "# You can add helper functions as well.\n",
    "def helper_function(i):\n",
    "    return i + 1\n",
    "\n",
    "@weight(3)\n",
    "@name(\"Add function — test multiple values\")\n",
    "@description(\"Test the add function on more inputs\")\n",
    "def test_add_multiple():\n",
    "    for i in range(10):\n",
    "        assert student.add(1, i) == helper_function(i), f\"Add was incorrect on input (1, {i})\"\n",
    "\n",
    "\n",
    "# NumPy has some very good assert functions.\n",
    "# On failure, numpy will report a nice and detailed message. \n",
    "# You can also set tolerance values, see the documentation.\n",
    "import numpy as np\n",
    "\n",
    "@weight(2.5)\n",
    "@name(\"Add function — test multiple values\")\n",
    "@description(\"Test the add function on more inputs\")\n",
    "def test_add_array():\n",
    "    np.testing.assert_allclose([student.add(1, i) for i in range(10)],\n",
    "                               [helper_function(i) for i in range(10)])\n",
    "        \n",
    "#!# END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fc25a-8e40-46bd-8e94-fbbadb14f0bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3 Checking tests locally <a class=\"anchor\" id=\"checking-tests-locally\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b99f53-9261-4b20-99c1-37c53500b11c",
   "metadata": {},
   "source": [
    "The `weight`,`name` and `description` decorators are not defined until running the tests in CodeGrade, which probably gave you an error when running the cell above. We can define them when developing the notebook, and also use them to automatically run the tests locally to check for correctness. You can paste the following code at the top of your notebook to do this. A `#!# BEGIN/END REMOVE_FOR TESTS` block will be removed when running the tests in CodeGrade and creating the student notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a7f1c07-54dc-48db-a0e7-da8945ba7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!# BEGIN REMOVE_FOR TESTS\n",
    "class Student():\n",
    "    def __init__(self):\n",
    "        # Load all current variables into the student class.\n",
    "        for key, value in globals().items():\n",
    "            exec(f\"self.{key} = {key}\")\n",
    "student = None\n",
    "\n",
    "def weight(w):\n",
    "    # Reload the variables into the student object.\n",
    "    global student\n",
    "    student = Student()\n",
    "    def decorator(func):\n",
    "        print(\"weight: \\t\", w)\n",
    "        # By putting the function call one layer higher\n",
    "        # here the test will automatically run.\n",
    "        func()\n",
    "        print(\"Test OK\\n\")\n",
    "        def inner():\n",
    "            pass\n",
    "        return inner\n",
    "    return decorator\n",
    "\n",
    "def name(name):\n",
    "    def decorator(func):\n",
    "        def inner():\n",
    "            print(\"name: \\t\\t\", name)\n",
    "            func()\n",
    "        return inner \n",
    "    return decorator\n",
    "\n",
    "def description(d):\n",
    "    def decorator(func):\n",
    "        def inner():\n",
    "            print(\"description: \\t\", d)\n",
    "            func()\n",
    "        return inner\n",
    "    return decorator\n",
    "\n",
    "#!# END REMOVE_FOR TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b64397-a754-4b32-804e-5ba3ddb697de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4 Setting up CodeGrade <a class=\"anchor\" id=\"codegrade\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f8a85-44f3-4bb7-b1c5-23961a81dbe0",
   "metadata": {},
   "source": [
    "### Creating the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fd4a78-1fa7-4f3c-b321-0f5dc147cfee",
   "metadata": {},
   "source": [
    "First create an assignment in Canvas, go to _Submission type_, select _External tool_ and select _CodeGra.de_ from the list. You can also set availability and deadlines here. They will be synced with CodeGrade.\n",
    "\n",
    "![Create assignment](tutorial-images/create-assignment.png)\n",
    "\n",
    "Now saving and opening the assignment shows the CodeGrade interface. If you want, press _New Tab_ on the bottom left to open the window in a new browser tab. Navigate to _Courses_ and then to your course. Your assignment should be listed here. Clicking on the assignment opens the submission window, which is used when grading. \n",
    "\n",
    "![CodeGrade window](tutorial-images/codegrade-window.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cba76b-1271-46d2-98f9-0d904cd5fae8",
   "metadata": {},
   "source": [
    "### Rubric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8337026e-3bfd-48dc-9ac0-532ccc1f5a11",
   "metadata": {},
   "source": [
    "Pressing the _cogwheel_ opens the assignment settings, which is where we will configure the rubric and autotests now. \n",
    "Navigate to the _Rubric_ tab and create a new rubric. For the autotests we need to use a _Continuous category_.\n",
    "\n",
    "![Autotest rubric](tutorial-images/rubric-continuous.png)\n",
    "\n",
    "You can also add a manually graded category alongside the autotests, which will often be _Discrete_.\n",
    "\n",
    "![Manually graded rubric](tutorial-images/rubric-discrete.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ac454-a0ce-4010-a0ab-9d06ff97c578",
   "metadata": {},
   "source": [
    "### Autotests — Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551a3e44-0576-4dac-b10a-0de0cac66ddc",
   "metadata": {},
   "source": [
    "Now we want to setup the autotests. Navigate to the _AutoTest_ tab and select _AutoTest V2_. If you have done the following steps before, you can select _Copy_ here, but for now select _Create_.\n",
    "\n",
    "![AutoTest Screen](tutorial-images/autotest-screen.png)\n",
    "\n",
    "Navigate to _Setup_. The Setup steps are run once for all students, so here we will install required packages and upload required files for autograding. \n",
    "Drag the _Upload files_ step to the left and upload your notebook (including the solutions and autotests) as well as `prepare.py`.\n",
    "\n",
    "![Setup screen](tutorial-images/setup-screen.png)\n",
    "\n",
    "Now drag the _Script_ step to the left and copy the following line to it: \n",
    "\n",
    "```bash\n",
    "python3 -m pip install notebook nbconvert nbval\n",
    "```\n",
    "\n",
    "Here you can install other Python packages your notebook needs as well (for instance, write `python3 -m pip install notebook nbconvert sympy numpy matplotlib` on the first line instead). \n",
    "\n",
    "Then drag another _Script_ step below it and copy the following line to it:\n",
    "```bash\n",
    "python3 $UPLOADED_FILES/prepare.py solutions\n",
    "```\n",
    "\n",
    "You can also name the steps if you want. Your setup steps should now look something like this:\n",
    "\n",
    "![Setup scripts](tutorial-images/setup.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd06ab0-95de-480b-b7d6-3588adc6b7fe",
   "metadata": {},
   "source": [
    "### Autotests — Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961e68e-44f2-4749-88a9-e63741c31e6e",
   "metadata": {},
   "source": [
    "Next, navigate to _Tests_, drag a _Script_ step to the left and paste the following into it:\n",
    "```bash\n",
    "python3 $UPLOADED_FILES/prepare.py hand-in\n",
    "```\n",
    "\n",
    "Now drag a _Connect Rubric_ step to the left, and link it to the _AutoTest_ rubric category. \n",
    "Then drag a _Pytest_ step into the _Connect Rubric_ step and paste the following into it:\n",
    "\n",
    "```python\n",
    "import prepare\n",
    "exec(prepare.tests(\"VISIBLE\"))\n",
    "```\n",
    "\n",
    "This will extract all visible tests from the notebook. We can do the same for the hidden tests. For this we first drag a _Hidden_ step from the right to below the previous step, and place the same Pytest script inside it as before, but with `\"VISIBLE\"` changed to `\"HIDDEN\"`. Set the _Hidden_ step to _result | before | deadline_.\n",
    "\n",
    "CodeGrade will assign equal weight to every Pytest step (so the visible and hidden tests will have equal weight). In many cases this is not what we want, so we will add _Weight_ steps around the two Pytest steps, and set the weight to equal the total amount of weight set in your tests. Unfortunately, you have to set this weight manually every time you change the point total.\n",
    "\n",
    "Your steps should then look something like this: \n",
    "\n",
    "![Tests scripts everything](tutorial-images/tests-all.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e4d3e-80fd-4d62-a9f5-7da19dc7a5da",
   "metadata": {},
   "source": [
    "### Autotests — Building a snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ae3528-1c36-4fc2-bb7d-78909b45e165",
   "metadata": {},
   "source": [
    "We're almost done! Press _Build Snapshot_ on the bottom right and upload the solutions notebook as the test submission (you can reupload this under the _General_ tab). Now CodeGrade will run the setup and test steps. This might take a while.\n",
    "Any error will be displayed to you. If everything went correctly you will see a list of your autotests appear. This is what students will see as well. Pressing _Publish to Students_ will start the tests for your students! \n",
    "\n",
    "![Autotest results](tutorial-images/test-results.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcaa7a5-6d26-49d5-b252-c2d938fcbfac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5 Student feedback <a class=\"anchor\" id=\"student-feedback\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce168c-9fc3-4d6d-b061-3eba4cae3077",
   "metadata": {},
   "source": [
    "Immediately after handing in, student's open up the \"Convert student notebook\" step in the AutoTests tab in their submission to check whether their notebook runs properly. The `F`'s here mean the corresponding cell raised an exception. \n",
    "\n",
    "![AutoTest Screen](tutorial-images/student-feedback-convert.png)\n",
    "\n",
    "Failed tests will look something like this. This example uses the `np.testing.assert_allclose` function.\n",
    "\n",
    "![AutoTest Screen](tutorial-images/student-feedback-numpy.png)\n",
    "\n",
    "In fact, failed tests will report all `stdout` output, so any `print` statements in your tests will be visible to students when the test failed. You can use this to give more feedback. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8011a34-7ec0-48ed-9646-2506d034ebc6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 6 Optional: Making the solutions available to students <a class=\"anchor\" id=\"solutions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249ac21d-1cd7-4dd7-958c-0bf12dd649b4",
   "metadata": {},
   "source": [
    "You can remove only the tests from the notebook by running\n",
    "\n",
    "```bash\n",
    "    $ python prepare.py remove-tests [solutions notebook].ipynb [solutions but no tests notebook].ipynb\n",
    "```\n",
    "with `[solutions notebook.ipynb]` the notebook with the solutions and tests. You can then share the resulting file with your students on Canvas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587c7897-d324-460b-aeef-4f64fae9ad5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 7 Optional: Link tests to specific CodeGrade rubrics <a class=\"anchor\" id=\"specific-rubrics\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc52db-13b4-41fa-a54c-fd388b027e9d",
   "metadata": {},
   "source": [
    "If you would like, you can link tests to specific rubric categories in CodeGrade, to provide more structure for your students. This is not too hard but requires some more effort to manually set things up in your notebook and CodeGrade. Because of this it is also not possible anymore to simply directly copy the CodeGrade AutoTests from a previous exercise.\n",
    "\n",
    "The basic idea is that you can give test blocks other categories than just `HIDDEN` or `VISIBLE`. In fact, you can write any category name you like. For instance, `QUESTION1_VISIBLE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60346028-8592-4a1e-8b28-cfd63f6350f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: \t 1\n",
      "name: \t\t Add function 1\n",
      "description: \t Testing if the add function can add 10 and 12 correctly.\n",
      "Test OK\n",
      "\n",
      "weight: \t 1\n",
      "name: \t\t Add function 2\n",
      "description: \t Testing if the add function can add 23 and 1 correctly.\n",
      "Test OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!# BEGIN QUESTION1_VISIBLE TESTS\n",
    "@weight(1)\n",
    "@name(\"Add function 1\")\n",
    "@description(\"Testing if the add function can add 10 and 12 correctly.\")\n",
    "def test_add_single():\n",
    "    assert student.add(10,12) == add(10,12), \"Add is incorrect\"\n",
    "#!# END QUESTION1_VISIBLE TESTS\n",
    "\n",
    "#!# BEGIN QUESTION1_VISIBLE TESTS\n",
    "@weight(1)\n",
    "@name(\"Add function 2\")\n",
    "@description(\"Testing if the add function can add 23 and 1 correctly.\")\n",
    "def test_add_single():\n",
    "    assert student.add(23,1) == add(23,1), \"Add is incorrect\"\n",
    "#!# END QUESTION1_VISIBLE TESTS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c7585-071e-4ba6-8e47-7ca9f1d87d8a",
   "metadata": {},
   "source": [
    "Then in the rubric add a rubric items however you would like, for instance as below. Remember to make autotested items a continuous category.\n",
    "\n",
    "![Mutiple rubric items](tutorial-images/multiple-rubric.png)\n",
    "\n",
    "Then in the autotest screen link up the autotests one-by-one, replacing the `\"VISIBLE\"` string in the script from before with whatever category names you chose (this is case sensitive!). If your question only has visible or hidden tests, you can leave out the _Weight_ steps. \n",
    "Remember to use the duplication feature (available by clicking the three dots of the _Connect Rubric_ step) to make your live easier! \n",
    "\n",
    "![Mutiple test items](tutorial-images/multiple-tests.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
